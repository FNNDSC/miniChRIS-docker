# an ephemeral instance of ChRIS backend services for local development
#
# warning: /var/run/docker.sock is mounted into some services (notably pman)

services:
  chrisomatic:
    image: ghcr.io/fnndsc/chrisomatic:0.8.3
    profiles:
      - tools
    volumes:
      - "./chrisomatic.yml:/chrisomatic.yml:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:rw"
    userns_mode: host
    depends_on:
      - chris
    networks:
      - local

  db_migrate:
    image: ghcr.io/fnndsc/cube:5.0.0
    command: python manage.py migrate --noinput
    env_file: secrets.env
    volumes:
      - chris_files:/data:rw
    depends_on:
      db:
        condition: service_healthy
    networks:
      - local
  
  chris:
    container_name: chris
    image: ghcr.io/fnndsc/cube:5.0.0
    ports:
      - "8000:8000"
    volumes:
      - chris_files:/data:rw
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      queue:
        condition: service_started
    networks:
      - local
    env_file: secrets.env
    labels:
      org.chrisproject.role: "ChRIS_ultron_backEnd"
      org.chrisproject.miniChRIS: "miniChRIS"
  worker:
    image: ghcr.io/fnndsc/cube:5.0.0
    command: celery -A core worker -c 4 -l info -Q main1,main2
    volumes:
      - chris_files:/data:rw
    env_file: secrets.env
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      queue:
        condition: service_started
      pfcon:
        condition: service_started
    restart: unless-stopped
    networks:
      - local
  worker_periodic:
    image: ghcr.io/fnndsc/cube:5.0.0
    command: celery -A core worker -c 2 -l info -Q periodic
    volumes:
      - chris_files:/data:rw
    env_file: secrets.env
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      queue:
        condition: service_started
    restart: unless-stopped
    networks:
      - local
  scheduler:
    image: ghcr.io/fnndsc/cube:5.0.0
    command: celery -A core beat -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    volumes:
      - chris_files:/data:rw
    env_file: secrets.env
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      queue:
        condition: service_started
    restart: unless-stopped
    networks:
      - local
  db:
    image: docker.io/library/postgres:16
    env_file: secrets.env
    restart: unless-stopped
    volumes:
      - db_data:/var/lib/postgresql/data
    networks:
      - local
    healthcheck:
      test: ["CMD", "pg_isready"]
      interval: 2s
      timeout: 4s
      retries: 3
      start_period: 60s
  queue:
    image: docker.io/library/rabbitmq:3
    restart: on-failure
    networks:
      - local

  pfcon:
    container_name: pfcon
    image: ghcr.io/fnndsc/pfcon:5.2.2
    environment:
      COMPUTE_SERVICE_URL: http://pman:5010/api/v1/
      SECRET_KEY: secret
      PFCON_USER: pfcon
      PFCON_PASSWORD: pfcon1234
      PFCON_INNETWORK: "true"
      STORAGE_ENV: filesystem
      STOREBASE_MOUNT: /var/local/storeBase
    ports:
      - "5005:5005"
    volumes:
      - chris_files:/var/local/storeBase
    networks:
      local:
        aliases:
          - pfcon.host
      remote:
    labels:
      org.chrisproject.role: "pfcon"
    user: "1001"

  pman:
    image: ghcr.io/fnndsc/pman:6.2.0
    container_name: pman
    environment:
      CONTAINER_ENV: docker
      CONTAINER_USER: "1001:"
      ENABLE_HOME_WORKAROUND: "yes"
      JOB_LABELS: "org.chrisproject.miniChRIS=plugininstance"
      SECRET_KEY: secret
      REMOVE_JOBS: "yes"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:rw
    depends_on:
      - pfcon
    ports:
      - "5010:5010"
    networks:
      remote:
    userns_mode: "host"
    labels:
      org.chrisproject.role: "pman"

  chris_ui:
    image: ghcr.io/fnndsc/chris_ui:20240507.446-767958ca
    command: sirv --host --single
    environment:
      REACT_APP_CHRIS_UI_URL: http://localhost:8000/api/v1/
      REACT_APP_PFDCM_URL: http://localhost:4005/
    ports:
      - "8020:3000"

  orthanc:
    image: docker.io/jodogne/orthanc-plugins:1.12.3
    volumes:
      - ./orthanc.json:/etc/orthanc/orthanc.json:ro
      - orthanc:/var/lib/orthanc/db
    ports:
      - "4242:4242"
      - "8042:8042"
    networks:
      - pacs
    profiles:
      - pacs
      - orthanc

  pfdcm:
    image: ghcr.io/fnndsc/pfdcm:3.1.2
    container_name: pfdcm
    environment:
      MAX_WORKERS: 1
    volumes:
      - pfdcm:/home/dicom:rw
      - ./pfdcm-services:/home/dicom/services:ro
      - chris_files:/chris_files:rw
    ports:
      - "4005:4005"
    networks:
      - pacs
    user: "1001"
    profiles:
      - pacs

  oxidicom:
    image: ghcr.io/fnndsc/oxidicom:2.0.0
    environment:
      OXIDICOM_DB_CONNECTION: postgresql://chris:chris1234@db:5432/chris
      OXIDICOM_FILES_ROOT: /data
      OXIDICOM_SCP_AET: ChRIS
      OXIDICOM_PACS_ADDRESS: '{MINICHRISORTHANC="orthanc:4242"}'
      OXIDICOM_SCP_PROMISCUOUS: "true"
      OXIDICOM_DB_BATCH_SIZE: 20
      OXIDICOM_LISTENER_THREADS: 32
      OXIDICOM_VERBOSE: "true"
      OXIDICOM_LISTENER_PORT: 11111
    volumes:
      - chris_files:/data:rw
    networks:
      - pacs
      - local
    profiles:
      - pacs
    user: 1001:0
  pfbridge:
    image: docker.io/fnndsc/pfbridge:3.7.2
    container_name: pfbridge
    environment:
      MAX_WORKERS: 1
      PFLINK_USERNAME: pflink
      PFLINK_PASSWORD: pflink1234
      NAME: PFDCMLOCAL
      PACSNAME: orthanc
      CUBEANDSWIFTKEY: local
    ports:
      - "33333:33333"
    networks:
      local:
      pflink:
    profiles:
      - pflink

  pflink:
    image: docker.io/fnndsc/pflink:settings-39e91ed
    container_name: pflink
    restart: unless-stopped
    environment:
      PFDCM_NAME: "NOTPFDCMLOCAL"  # work around for hard-coded edge case
      PFLINK_MONGODB: "mongodb://pflink-db:27017"
      PFLINK_PFDCM: "http://pfdcm:4005"
      PFLINK_PORT: "4010"
    ports:
      - "4010:4010"
    networks:
      local:
      pflink:
    depends_on:
      - pflink-db
    profiles:
      - pflink

  pflink-db:
    image: mongo
    environment:
      - PUID=1000
      - PGID=1000
    volumes:
      - pflink-db-data:/data/db
    restart: unless-stopped
    networks:
      pflink:
    profiles:
      - pflink

  graphql-engine:
    image: docker.io/hasura/graphql-engine:v2.40.0
    ports:
      - "8090:8080"
    restart: unless-stopped
    environment:
      ## postgres database to store Hasura metadata
      HASURA_GRAPHQL_METADATA_DATABASE_URL: postgres://hasura:hasura1234@hasura-db:5432/hasura
      ## this env var can be used to add the above postgres database to Hasura as a data source. this can be removed/updated based on your needs
      PG_DATABASE_URL: postgres://chris:chris1234@chris_db:5432/chris
      ## enable the console served by server
      HASURA_GRAPHQL_ENABLE_CONSOLE: "true" # set to "false" to disable console
      ## enable debugging mode. It is recommended to disable this in production
      HASURA_GRAPHQL_DEV_MODE: "true"
      HASURA_GRAPHQL_ENABLED_LOG_TYPES: startup, http-log, webhook-log, websocket-log, query-log
      ## uncomment next line to run console offline (i.e load console assets from server instead of CDN)
      HASURA_GRAPHQL_CONSOLE_ASSETS_DIR: /srv/console-assets
      ## uncomment next line to set an admin secret
      # HASURA_GRAPHQL_ADMIN_SECRET: myadminsecretkey
      HASURA_GRAPHQL_METADATA_DEFAULTS: '{"backend_configs":{"dataconnector":{"athena":{"uri":"http://data-connector-agent:8081/api/v1/athena"},"mariadb":{"uri":"http://data-connector-agent:8081/api/v1/mariadb"},"mysql8":{"uri":"http://data-connector-agent:8081/api/v1/mysql"},"oracle":{"uri":"http://data-connector-agent:8081/api/v1/oracle"},"snowflake":{"uri":"http://data-connector-agent:8081/api/v1/snowflake"}}}}'
    depends_on:
      hasura-db:
        condition: service_healthy
      data-connector-agent:
        condition: service_healthy
    networks:
      local:
    profiles:
      - hasura
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/healthz?strict=false"]
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 5s
  data-connector-agent:
    image: hasura/graphql-data-connector:v2.40.0
    restart: unless-stopped
    ports:
      - 8081:8081
    environment:
      QUARKUS_LOG_LEVEL: ERROR # FATAL, ERROR, WARN, INFO, DEBUG, TRACE
      ## https://quarkus.io/guides/opentelemetry#configuration-reference
      QUARKUS_OPENTELEMETRY_ENABLED: "false"
      ## QUARKUS_OPENTELEMETRY_TRACER_EXPORTER_OTLP_ENDPOINT: http://jaeger:4317
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081/api/v1/athena/health"]
      interval: 5s
      timeout: 10s
      retries: 5
      start_period: 5s
    networks:
      local:
    profiles:
      - hasura
  hasura-db:
    image: docker.io/library/postgres:15
    restart: unless-stopped
    volumes:
      - hasura-db-data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: hasura
      POSTGRES_PASSWORD: hasura1234
      POSTGRES_DB: hasura
    networks:
      local:
    profiles:
      - hasura
    healthcheck:
      test: ["CMD", "pg_isready"]
      interval: 2s
      timeout: 4s
      retries: 3
      start_period: 60s
  hasura-cli:
    image: ghcr.io/fnndsc/hasura-cli:2.41.0
    command: hasura metadata apply
    restart: "no"
    volumes:
      - ./hasura:/hasura:ro
    working_dir: /hasura
    networks:
      local:
    profiles:
      - hasura
    depends_on:
      graphql-engine:
        condition: service_healthy

  # Non-root container user workarounds

  cube-nonroot-user-volume-fix:
    image: docker.io/library/alpine:latest
    volumes:
      - chris_files:/data:rw
    user: root
    command: chmod g+rwx /data
    restart: "no"

  pfdcm-nonroot-user-volume-fix:
    image: docker.io/library/alpine:latest
    volumes:
      - pfdcm:/home/dicom:rw
    user: root
    command: chown 1001 /home/dicom
    restart: "no"

networks:
  local:
    name: minichris-local
  remote:
  pacs:
  monitoring:
  pflink:

volumes:
  chris_files:
    name: minichris-files
  db_data:
  orthanc:
  pfdcm:
  grafana_data:
  openobserve_data:
  pflink-db-data:
  hasura-db-data:
