# an ephemeral instance of ChRIS backend services for local development
#
# warning: /var/run/docker.sock is mounted into some services (notably pman)

version: '3.9'

services:
  chrisomatic:
    image: ghcr.io/fnndsc/chrisomatic:0.6.0
    profiles:
      - tools
    volumes:
      - "./chrisomatic.yml:/chrisomatic.yml:ro"
      - "/var/run/docker.sock:/var/run/docker.sock:rw"
    userns_mode: host
    depends_on:
      - chris
    networks:
    - local

  db_migrate:
    image: ghcr.io/fnndsc/cube:5.0.0
    command: python manage.py migrate --noinput
    env_file: secrets.env
    volumes:
      - chris_files:/data:rw
    depends_on:
      db:
        condition: service_healthy
    networks:
      - local
  
  chris:
    container_name: chris
    image: ghcr.io/fnndsc/cube:5.0.0
    ports:
      - "8000:8000"
    volumes:
      - chris_files:/data:rw
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      queue:
        condition: service_started
    networks:
      - local
    env_file: secrets.env
    labels:
      org.chrisproject.role: "ChRIS_ultron_backEnd"
      org.chrisproject.miniChRIS: "miniChRIS"
  worker:
    image: ghcr.io/fnndsc/cube:5.0.0
    command: celery -A core worker -c 4 -l info -Q main1,main2
    volumes:
      - chris_files:/data:rw
    env_file: secrets.env
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      queue:
        condition: service_started
      pfcon:
        condition: service_started
    restart: unless-stopped
    networks:
      - local
  worker_periodic:
    image: ghcr.io/fnndsc/cube:5.0.0
    command: celery -A core worker -c 2 -l info -Q periodic
    volumes:
      - chris_files:/data:rw
    env_file: secrets.env
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      queue:
        condition: service_started
    restart: unless-stopped
    networks:
      - local
  scheduler:
    image: ghcr.io/fnndsc/cube:5.0.0
    command: celery -A core beat -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    volumes:
      - chris_files:/data:rw
    env_file: secrets.env
    depends_on:
      db_migrate:
        condition: service_completed_successfully
      queue:
        condition: service_started
    restart: unless-stopped
    networks:
      - local
  db:
    image: docker.io/library/postgres:16
    env_file: secrets.env
    restart: unless-stopped
    volumes:
      - db_data:/var/lib/postgresql/data
    networks:
      - local
    healthcheck:
      test: ["CMD", "pg_isready"]
      interval: 2s
      timeout: 4s
      retries: 3
      start_period: 60s
  queue:
    image: docker.io/library/rabbitmq:3
    restart: unless-stopped
    networks:
      - local

  pfcon:
    container_name: pfcon
    image: ghcr.io/fnndsc/pfcon:5.2.2
    environment:
      COMPUTE_SERVICE_URL: http://pman:5010/api/v1/
      SECRET_KEY: secret
      PFCON_USER: pfcon
      PFCON_PASSWORD: pfcon1234
      PFCON_INNETWORK: "true"
      STORAGE_ENV: filesystem
      STOREBASE_MOUNT: /var/local/storeBase
    ports:
      - "5005:5005"
    volumes:
      - chris_files:/var/local/storeBase
    networks:
      local:
        aliases:
          - pfcon.host
      remote:
    labels:
      org.chrisproject.role: "pfcon"
    user: "1001"

  pman:
    image: ghcr.io/fnndsc/pman:6.0.1
    container_name: pman
    environment:
      CONTAINER_ENV: docker
      CONTAINER_USER: "1001:"
      ENABLE_HOME_WORKAROUND: "yes"
      JOB_LABELS: "org.chrisproject.miniChRIS=plugininstance"
      SECRET_KEY: secret
      REMOVE_JOBS: "yes"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:rw
    depends_on:
      - pfcon
    ports:
      - "5010:5010"
    networks:
      remote:
    userns_mode: "host"
    labels:
      org.chrisproject.role: "pman"

  chris_ui:
    image: ghcr.io/fnndsc/chris_ui:20230901.263-b2c5dabe
    command: sirv --host --single
    environment:
      REACT_APP_CHRIS_UI_URL: http://localhost:8000/api/v1/
      REACT_APP_PFDCM_URL: http://localhost:4005/
    ports:
      - "8020:3000"

  orthanc:
    image: docker.io/jodogne/orthanc-plugins:1.11.0
    volumes:
      - ./orthanc.json:/etc/orthanc/orthanc.json:ro
      - orthanc:/var/lib/orthanc/db
    ports:
      - "4242:4242"
      - "8042:8042"
    networks:
      - pacs

  pfdcm:
    image: ghcr.io/fnndsc/pfdcm:3.1.2
    container_name: pfdcm
    environment:
      MAX_WORKERS: 1
    volumes:
      - pfdcm:/home/dicom:rw
      - ./pfdcm-services:/home/dicom/services:ro
      - chris_files:/chris_files:rw
    ports:
      - "4005:4005"
    networks:
      - pacs
      - local
    user: "1001"

  pfdcm-listener:
    image: ghcr.io/fnndsc/pypx-listener:0.4.0
    volumes:
      - pfdcm:/home/dicom:rw
    networks:
      - pacs
    user: "1001"
    restart: unless-stopped
    logging:
      driver: fluentd
      options:
        tag: rx-repack
    depends_on:
      - pfdcm-nonroot-user-volume-fix
      - fluentbit


  # Non-root container user workarounds

  cube-nonroot-user-volume-fix:
    image: docker.io/library/alpine:latest
    volumes:
      - chris_files:/data:rw
    user: root
    command: chmod g+rwx /data
    restart: "no"

  pfdcm-nonroot-user-volume-fix:
    image: docker.io/library/alpine:latest
    volumes:
      - pfdcm:/home/dicom:rw
    user: root
    command: chown 1001 /home/dicom
    restart: "no"

  # ====================
  # Monitoring
  # ====================

  grafana:
    image: docker.io/grafana/grafana-oss:9.0.7
    ports:
      - 9009:3000
    depends_on:
      - db
      - prometheus
    restart: unless-stopped
    networks:
      local:
      monitoring:
    volumes:
      - grafana_data:/var/lib/grafana
      - ./observability/grafana.ini:/etc/grafana/grafana.ini:ro
    profiles:
      - observability
  prometheus:
    image: quay.io/prometheus/prometheus:v2.37.0
    ports:
      - 9090:9090
    volumes:
      - ./observability/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    restart: unless-stopped
    networks:
      monitoring:
    depends_on:
      - cadvisor
    profiles:
      - observability
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.45.0
    ports:
      - 9008:8080
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
      - /dev/disk/:/dev/disk/:ro
    devices:
      - /dev/kmsg
    privileged: true
    userns_mode: host
    networks:
      monitoring:
    restart: unless-stopped
    profiles:
      - observability
  openobserve:
    image: public.ecr.aws/zinclabs/openobserve:v0.6.2
    ports:
      - 5080:5080
    volumes:
      - openobserve_data:/data:rw
    environment:
      ZO_DATA_DIR: /data
      ZO_ROOT_USER_EMAIL: "dev@babymri.org"
      ZO_ROOT_USER_PASSWORD: "chris1234"
    restart: unless-stopped
    networks:
      monitoring:
    profiles:
      - observability

  # Based on:
  # https://kevcodez.de/posts/2019-08-10-fluent-bit-docker-logging-driver-elasticsearch/
  # https://www.velebit.ai/blog/tech-blog-collecting-logs-in-docker-clusters/
  # must not be part of the "observability" profile because it's used as a log driver
  fluentbit:
    image: cr.fluentbit.io/fluent/fluent-bit:2.1.8
    command: /fluent-bit/bin/fluent-bit -c /fluent-bit/etc/fluent-bit.conf --enable-hot-reload
    ports:
      - "24224:24224"
      - "24224:24224/udp"
    volumes:
      - ./observability/fluent-bit:/fluent-bit/etc:ro
    networks:
      monitoring:

networks:
  local:
  remote:
  pacs:
  monitoring:

volumes:
  chris_files:
  db_data:
  orthanc:
  pfdcm:
  grafana_data:
  openobserve_data:
